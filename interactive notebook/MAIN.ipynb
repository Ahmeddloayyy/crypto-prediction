{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c94c5a-ce74-410f-8fb4-58c86ac00e97",
   "metadata": {},
   "source": [
    "1) DATA FETCHING & CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbdbcd-1446-4503-966f-d49f4a539d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# Define the list of top 30 cryptocurrencies\n",
    "crypto_list = [\n",
    "    'BTC-USD', 'ETH-USD', 'XRP-USD', 'LTC-USD', 'BCH-USD', 'ADA-USD', 'DOT-USD',\n",
    "    'BNB-USD', 'LINK-USD', 'XLM-USD', 'DOGE-USD', 'UNI-USD', 'AAVE-USD', 'ATOM-USD',\n",
    "    'AVAX-USD', 'MATIC-USD', 'SOL-USD', 'CHR-USD', 'ALGO-USD', 'FTT-USD', 'VET-USD',\n",
    "    'FIL-USD', 'TRX-USD', 'ETC-USD', 'XMR-USD', 'EOS-USD', 'THETA-USD', 'NEO-USD',\n",
    "    'DASH-USD', 'ZEC-USD'\n",
    "]\n",
    "\n",
    "# Fetch data for the last 5 years\n",
    "def fetch_crypto_data(cryptos, years=5):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=years * 365)  # Adjust for 5 years\n",
    "    data = yf.download(cryptos, start=start_date, end=end_date)['Close']\n",
    "    return data\n",
    "    \n",
    "crypto_data = fetch_crypto_data(crypto_list)\n",
    "# Handle missing values (fill forward and backward)\n",
    "crypto_data.ffill(axis=0, inplace=True)  \n",
    "crypto_data.bfill(axis=0, inplace=True)  \n",
    "\n",
    "# Save the cleaned data\n",
    "crypto_data.to_csv('Crypto.csv', index=True)\n",
    "# Adjust pandas display options to show all columns\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)        # No line breaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd82c4-9b52-4e62-b9fc-51f216dd904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace with your file path)\n",
    "crypto_data = pd.read_csv(\"Crypto.csv\")\n",
    "\n",
    "# Compute the range (min and max) for each cryptocurrency\n",
    "crypto_ranges = crypto_data.describe().loc[['min', 'max']].transpose()\n",
    "\n",
    "# Add a 10% buffer to min and max ranges\n",
    "crypto_ranges['min_with_buffer'] = crypto_ranges['min'] * 0.9  \n",
    "crypto_ranges['max_with_buffer'] = crypto_ranges['max'] * 1.1  \n",
    "# Save or display the ranges\n",
    "crypto_ranges.to_csv(\"Crypto_Ranges.csv\")\n",
    "print(crypto_ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831232e4-a822-4fff-9a76-188e2b7b9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter anomalies based on per-cryptocurrency thresholds\n",
    "def filter_anomalies_by_ticker(data, crypto_ranges):\n",
    "    \"\"\"\n",
    "    Filters out anomalies for each cryptocurrency based on provided ranges.\n",
    "    - data: DataFrame with cryptocurrencies as columns.\n",
    "    - crypto_ranges: Dictionary with {ticker: (min, max)} ranges for valid prices.\n",
    "    \"\"\"\n",
    "    filtered_data = pd.DataFrame()\n",
    "    for ticker, (min_price, max_price) in crypto_ranges.items():\n",
    "        if ticker in data.columns:\n",
    "            filtered_data[ticker] = data[ticker].where(\n",
    "                (data[ticker] >= min_price) & (data[ticker] <= max_price)\n",
    "            )\n",
    "    return filtered_data.dropna(axis=1, how=\"all\")  # Drop columns entirely NaN\n",
    "\n",
    "# Define reasonable ranges for each cryptocurrency\n",
    "crypto_price_ranges = {\n",
    "    'BTC-USD': (4473.71, 116754.66),  \n",
    "    'ETH-USD': (99.55, 5293.30),    \n",
    "    'XRP-USD': (0.13, 2.99),        \n",
    "    'LTC-USD': (27.84, 425.10),\n",
    "    'AAVE-USD': (0.46, 695.49),\n",
    "    'ALGO-USD': (0.08, 2.62),\n",
    "    'ATOM-USD': (1.48, 49.00),\n",
    "    'AVAX-USD': (2.62, 147.98),\n",
    "    'BCH-USD': (80.42, 1696.67),\n",
    "    'BNB-USD': (8.45, 825.30),\n",
    "    'CHR-USD': (0.01, 1.550),\n",
    "    'DASH-USD': (19.31, 484.98),\n",
    "    'DOGE-USD': (0.0014, 0.75),\n",
    "    'DOT-USD': (2.59, 59.27),\n",
    "    'EOS-USD': (0.37, 15.80),\n",
    "    'ETC-USD': (3.57,147.51),\n",
    "    'FIL-USD': (2.18,210.49),\n",
    "    'FTT-USD': (0.73, 87.86),\n",
    "    'LINK-USD': (1.57, 57.42),\n",
    "    'MATIC-USD': (0.0073, 3.16),\n",
    "    'NEO-USD': (4.84, 134.95),\n",
    "    'SOL-USD': (0.46, 284.83), \n",
    "    'THETA-USD': (0.05, 15.71),\n",
    "    'TRX-USD': (0.0079, 0.47),\t\n",
    "    'UNI-USD': (0.00003, 0.66),\t\n",
    "    'VET-USD': (0.0020, 0.28),\n",
    "    'XLM-USD': (0.03, 0.80), \n",
    "    'XMR-USD': (29.71, 531.94),\n",
    "    'ZEC-USD': (16.46, 350.81),\t\n",
    "    'ADA-USD': (0.02, 3.27)    \n",
    "}\n",
    "\n",
    "# Apply the anomaly filtering\n",
    "crypto_data_cleaned = filter_anomalies_by_ticker(crypto_data, crypto_price_ranges)\n",
    "\n",
    "# Load the data with proper headers and indices\n",
    "file_path = \"Crypto.csv\"  # Replace with your file path\n",
    "crypto_data = pd.read_csv(file_path, header=0, index_col=0)\n",
    "\n",
    "# Transpose the data to make cryptocurrencies rows and dates columns\n",
    "crypto_data_transposed = crypto_data.transpose()\n",
    "\n",
    "# Save the transposed data for clustering\n",
    "crypto_data_transposed.to_csv(\"Crypto_For_Clustering.csv\", index=True)\n",
    "\n",
    "# Load the data and set 'Unnamed: 0' as the index\n",
    "crypto_data = pd.read_csv(\"Crypto_For_Clustering.csv\", index_col=0)\n",
    "\n",
    "# Save the cleaned data\n",
    "crypto_data_transposed.to_csv('Cleaned_Crypto.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109dc8c-1c8d-407a-949c-ae68c37c44fe",
   "metadata": {},
   "source": [
    "2) CLUSTERING: 3 Clusters Based on proxmitiy on centroids, 1 Cluster based on recent growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d99826-af92-4fb6-baae-d338dd929b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2a: Load the updated 5-year dataset\n",
    "file_path = 'C:/Users/Ahmed/Desktop/APPLIED AI/Cleaned_Crypto.csv'\n",
    "crypto_data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2b: Check if Tickers are in the index or a column\n",
    "if \"Unnamed: 0\" in crypto_data.columns:\n",
    "    crypto_data.rename(columns={\"Unnamed: 0\": \"Ticker\"}, inplace=True)  \n",
    "    crypto_data.set_index(\"Ticker\", inplace=True)  \n",
    "\n",
    "# Prepare the data for PCA (use numerical price data only)\n",
    "price_data = crypto_data.copy()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(price_data)\n",
    "\n",
    "# Apply PCA (retain 2 components for visualization and clustering)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(standardized_data)\n",
    "\n",
    "# Step: Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "clusters = kmeans.fit_predict(pca_result)\n",
    "\n",
    "crypto_data[\"Cluster\"] = clusters\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=clusters, cmap='viridis', s=50)\n",
    "plt.title(\"Cryptocurrency Clusters (Standardized Data + PCA)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()\n",
    "\n",
    "# Select representatives based on proximity to centroids\n",
    "cluster_centroids = kmeans.cluster_centers_\n",
    "representatives = []\n",
    "for i in range(4):  # For each cluster\n",
    "    cluster_indices = np.where(clusters == i)[0]\n",
    "    distances = np.linalg.norm(pca_result[cluster_indices] - cluster_centroids[i], axis=1)\n",
    "    closest_index = cluster_indices[np.argmin(distances)]\n",
    "    representatives.append(price_data.index[closest_index])\n",
    "\n",
    "# Refine representative for Cluster 0 based on recent growth\n",
    "# Find cryptocurrency in Cluster 0 with the highest recent growth\n",
    "cluster_0_indices = crypto_data[crypto_data[\"Cluster\"] == 0].index\n",
    "cluster_0_prices = price_data.loc[cluster_0_indices]\n",
    "\n",
    "# Calculate growth over the last year (e.g., last 365 days)\n",
    "recent_growth = cluster_0_prices.iloc[:, -365:].mean(axis=1)\n",
    "representative_high_growth = recent_growth.idxmax()\n",
    "\n",
    "# Update the representative for Cluster 0\n",
    "representatives[0] = representative_high_growth\n",
    "\n",
    "# Print the final selected representatives\n",
    "print(\"Final Selected Representatives for Each Cluster:\")\n",
    "for cluster_id, representative in enumerate(representatives):\n",
    "    print(f\"Cluster {cluster_id}: {representative}\")\n",
    "\n",
    "# Save the updated dataset with cluster information\n",
    "crypto_data.to_csv('C:/Users/Ahmed/Desktop/APPLIED AI/Clustering.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ba913-04ab-4b15-8822-27b4a9c413fb",
   "metadata": {},
   "source": [
    "3) CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654274e-0847-43d5-8fdc-e6a8daaf7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File path for your input data\n",
    "file_path = \"C:/Users/Ahmed/Desktop/COM724/Clustering.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "if \"Cluster\" in data.columns:\n",
    "    data = data.drop(columns=[\"Cluster\"])\n",
    "\n",
    "if \"Ticker\" in data.columns:\n",
    "    data = data.set_index(\"Ticker\")\n",
    "\n",
    "#: Transpose the data\n",
    "# Transpose so that rows become dates and columns become cryptocurrency tickers\n",
    "price_data_t = data.transpose()\n",
    "\n",
    "#  Compute the correlation matrix\n",
    "# Calculate pairwise correlations between cryptocurrencies\n",
    "correlation_matrix = price_data_t.corr()\n",
    "\n",
    "#  Define specific representatives for correlation analysis\n",
    "representatives = [\"SOL-USD\", \"BTC-USD\", \"ETH-USD\", \"XMR-USD\"]  # Focused tickers\n",
    "\n",
    "# Step 3d: Verify representatives exist in the correlation matrix\n",
    "valid_representatives = [rep for rep in representatives if rep in correlation_matrix.columns]\n",
    "print(\"Valid Representatives:\", valid_representatives)\n",
    "\n",
    "# Step 3e: Extract top correlations for the specific representatives\n",
    "correlation_results = []  # List to store results for CSV export\n",
    "top_correlations = {}  # For in-memory display\n",
    "\n",
    "for rep in valid_representatives:\n",
    "    # Get correlations for the representative\n",
    "    correlations = correlation_matrix[rep]\n",
    "\n",
    "    # Sort and extract top 4 positive and top 4 negative correlations\n",
    "    top_positive = correlations.sort_values(ascending=False).iloc[1:5]  # Skip self-correlation\n",
    "    top_negative = correlations.sort_values(ascending=True).iloc[:4]\n",
    "\n",
    "    # Store top correlations in a dictionary for display\n",
    "    top_correlations[rep] = {\n",
    "        \"Top Positive\": top_positive,\n",
    "        \"Top Negative\": top_negative\n",
    "    }\n",
    "\n",
    "    # Store results for CSV export\n",
    "    for ticker, value in top_positive.items():\n",
    "        correlation_results.append({\n",
    "            \"Representative\": rep,\n",
    "            \"Type\": \"Top Positive\",\n",
    "            \"Ticker\": ticker,\n",
    "            \"Correlation\": value\n",
    "        })\n",
    "    for ticker, value in top_negative.items():\n",
    "        correlation_results.append({\n",
    "            \"Representative\": rep,\n",
    "            \"Type\": \"Top Negative\",\n",
    "            \"Ticker\": ticker,\n",
    "            \"Correlation\": value\n",
    "        })\n",
    "\n",
    "# Step 3f: Display results\n",
    "for rep, corr in top_correlations.items():\n",
    "    print(f\"Representative: {rep}\")\n",
    "    print(\"Top Positive Correlations:\")\n",
    "    print(corr[\"Top Positive\"])\n",
    "    print(\"Top Negative Correlations:\")\n",
    "    print(corr[\"Top Negative\"])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Step 3g: Save correlation results to a DataFrame and export as CSV\n",
    "correlation_results_df = pd.DataFrame(correlation_results)\n",
    "\n",
    "# Step 4: Visualize the correlation matrix as a heatmap (only for the selected representatives)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Cryptocurrency Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532e567-f06a-4799-a892-84ae4c9b815e",
   "metadata": {},
   "source": [
    "4) EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec5d23-8c30-4d57-a7db-f9cbfa63558c",
   "metadata": {},
   "source": [
    "1. Plot Historical Price Trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4faf79-d58b-4977-a817-50ff63f7373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Ensure the column names (dates) are in datetime format\n",
    "price_data.columns = pd.to_datetime(price_data.columns, errors='coerce')\n",
    "\n",
    "# Plot historical price trends for each representative\n",
    "for rep in representatives:  # Assuming 'representatives' is a list of tickers\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot the data for the current ticker\n",
    "    plt.plot(price_data.columns, price_data.loc[rep], linewidth=2, label=f\"Price Trend for {rep}\")\n",
    "    \n",
    "    # Add a title and labels\n",
    "    plt.title(f\"Historical Price Trend: {rep}\", fontsize=16)\n",
    "    plt.xlabel(\"Date\", fontsize=14)\n",
    "    plt.ylabel(\"Price\", fontsize=14)\n",
    "    \n",
    "    # Format the x-axis for dates\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=6))  # Show ticks every 6 months\n",
    "    plt.xticks(rotation=45, fontsize=10)\n",
    "    \n",
    "    # Add grid and legend\n",
    "    plt.grid(color='lightgray', linestyle='--', linewidth=0.5)\n",
    "    plt.legend(loc=\"upper left\", fontsize=12)\n",
    "    \n",
    "    # Ensure the layout is tight\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce6df7-03b1-405b-ae5e-bce05bebd666",
   "metadata": {},
   "source": [
    "2. Analyze Price Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4797729-1b23-46c6-bfcf-8691e768b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "for rep in representatives:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(price_data.loc[rep], bins=50, kde=True, label=f\"Price Distribution for {rep}\")\n",
    "    plt.title(f\"Price Distribution: {rep}\")\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot for price distribution\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=price_data.loc[rep])\n",
    "    plt.title(f\"Boxplot of Prices: {rep}\")\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c77df7e-caa2-4333-88d2-6458ef6c9a47",
   "metadata": {},
   "source": [
    "3. Analyze Returns (Daily)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a32403-97dd-4b52-8163-c750c3cc7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily percentage changes (returns)\n",
    "price_returns = price_data.pct_change()\n",
    "\n",
    "for rep in representatives:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(price_returns.loc[rep], label=f\"Daily Returns for {rep}\")\n",
    "    plt.title(f\"Daily Percentage Returns: {rep}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Daily Returns\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58916be-8c39-423b-b15b-87665665ef88",
   "metadata": {},
   "source": [
    "4. Distribution of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff25743-81d5-4eff-9b04-8658b3aafbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns (percentage changes)\n",
    "returns = price_data.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cb258-f118-4de5-a62f-931bc4360191",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in representatives:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(returns.loc[rep].dropna(), bins=50, kde=True, label=f\"Daily Returns: {rep}\")\n",
    "    plt.title(f\"Distribution of Daily Returns: {rep}\")\n",
    "    plt.xlabel(\"Daily Return (%)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "for rep in representatives:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=returns.loc[rep].dropna())  # Drop NaN values\n",
    "    plt.title(f\"Boxplot of Daily Returns: {rep}\")\n",
    "    plt.xlabel(\"Daily Return (%)\")\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4720e8-37c7-4d04-9701-b437e34508b6",
   "metadata": {},
   "source": [
    "MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f7e0c3-d6e8-4199-ac15-b12e35ec401f",
   "metadata": {},
   "source": [
    "FACEBOOK PROPHET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294622f-ae5c-410f-a927-fe6bbfc5eae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install prophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31472ad0-a4d3-4958-864b-e3c7669ffaf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure representatives are defined\n",
    "representatives = ['SOL-USD', 'BTC-USD', 'ETH-USD', 'XMR-USD']\n",
    "\n",
    "# Remove non-date columns from price_data\n",
    "price_data_dates = price_data.drop(columns=['Cluster'], errors='ignore')\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "for rep in representatives:\n",
    "    if rep in price_data_dates.index:  # Ensure the representative exists in price_data\n",
    "        # Create a new DataFrame with required format\n",
    "        data = price_data_dates.loc[rep].reset_index()\n",
    "        data.columns = ['ds', 'y']  # Prophet requires 'ds' (date) and 'y' (value)\n",
    "\n",
    "        # Ensure 'ds' is in datetime format\n",
    "        data['ds'] = pd.to_datetime(data['ds'], errors='coerce')  # Convert to datetime\n",
    "        data = data.dropna(subset=['ds'])  # Drop rows with invalid dates\n",
    "\n",
    "        # Initialize the Prophet model and add custom seasonality\n",
    "        model = Prophet(weekly_seasonality=False, yearly_seasonality=True)\n",
    "        # Fit the model\n",
    "        model.fit(data)\n",
    "\n",
    "        # Create a future DataFrame for the forecast\n",
    "        future = model.make_future_dataframe(periods=30)  # Predict for the next 30 days\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Plot the forecast\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        model.plot(forecast)\n",
    "        plt.title(f\"Facebook Prophet Forecast for {rep}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        # Display the forecasted data\n",
    "        print(f\"Forecasted Prices for {rep}:\\n\", forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(10))\n",
    "    else:\n",
    "        print(f\"Representative {rep} not found in the data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527749f-36fc-479b-9bf7-f62670938ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "\n",
    "# Define a function for evaluation\n",
    "def evaluate_prophet_model(rep, price_data):\n",
    "    # Prepare the data for Prophet\n",
    "    # Drop non-date columns like 'Cluster' and reset index\n",
    "    price_data_clean = price_data.drop(columns=['Cluster'], errors='ignore')\n",
    "    data = price_data_clean.loc[rep].reset_index()\n",
    "    data.columns = ['ds', 'y']  # Prophet requires 'ds' (date) and 'y' (value)\n",
    "\n",
    "    # Ensure 'ds' is in datetime format\n",
    "    data['ds'] = pd.to_datetime(data['ds'], errors='coerce')\n",
    "    data = data.dropna(subset=['ds'])  # Drop rows with invalid dates\n",
    "\n",
    "    # Train-test split (last 30 days as test set)\n",
    "    train_data = data[:-30]\n",
    "    test_data = data[-30:]\n",
    "\n",
    "    # Train the Prophet model\n",
    "    model = Prophet()\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # Generate predictions for the test period\n",
    "    future = model.make_future_dataframe(periods=30)\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Extract predictions for the test period\n",
    "    forecast_test = forecast[forecast['ds'].isin(test_data['ds'])]\n",
    "    predictions = forecast_test['yhat'].values\n",
    "    actuals = test_data['y'].values\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    mape = np.mean(np.abs((actuals - predictions) / actuals)) * 100\n",
    "\n",
    "    print(f\"Evaluation Metrics for {rep}:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluate for each representative\n",
    "for rep in representatives:\n",
    "    evaluate_prophet_model(rep, price_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ae627-0d2e-4fba-853f-99f2f03be3c2",
   "metadata": {},
   "source": [
    "ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92680408-ab45-4834-a7bd-3ae1b4d94438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0d81a-ed0a-46c7-af94-8bce5e25b372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pmdarima import auto_arima\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loop through representatives\n",
    "for rep in representatives:\n",
    "    data = price_data.loc[rep]\n",
    "\n",
    "    # Drop the 'Cluster' entry if it exists\n",
    "    if \"Cluster\" in data.index:\n",
    "        data = data.drop(index=\"Cluster\", errors=\"ignore\")\n",
    "\n",
    "    # Convert index to datetime\n",
    "    data.index = pd.to_datetime(data.index, format='%Y-%m-%d', errors='coerce').dropna()\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    train_data = data[:-30]\n",
    "    test_data = data[-30:]\n",
    "\n",
    "    # Stationarity check using ADF Test\n",
    "    adf_test = adfuller(train_data)\n",
    "    print(f\"ADF Test for {rep}:\")\n",
    "    print(f\"ADF Statistic: {adf_test[0]:.4f}, p-value: {adf_test[1]:.4f}\")\n",
    "    print(\"Stationary\" if adf_test[1] < 0.05 else \"Non-Stationary\")\n",
    "\n",
    "    # If non-stationary, apply differencing\n",
    "    if adf_test[1] >= 0.05:\n",
    "        train_data_diff = train_data.diff().dropna()\n",
    "    else:\n",
    "        train_data_diff = train_data\n",
    "\n",
    "    \n",
    "\n",
    "    auto_arima_model = auto_arima(train_data_diff, seasonal=False, trace=True)\n",
    "    print(auto_arima_model.summary())\n",
    "\n",
    "    # Use the optimal order from Auto ARIMA\n",
    "    order = auto_arima_model.order\n",
    "    print(f\"Selected ARIMA Order: {order}\")\n",
    "\n",
    "# Fit ARIMA model using Auto ARIMA's suggested order\n",
    "    arima_model = ARIMA(train_data_diff, order=order)\n",
    "    arima_fit = arima_model.fit()\n",
    "\n",
    "    # Forecast the next 30 days\n",
    "    forecast_diff = arima_fit.forecast(steps=30)\n",
    "    \n",
    "    # Reverse differencing (if applied)\n",
    "    forecast = forecast_diff.cumsum() + train_data.iloc[-1] if adf_test[1] >= 0.05 else forecast_diff\n",
    "    forecast.index = test_data.index\n",
    "\n",
    "    # Plot Training Data, Actual Test Data, and Forecast\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_data.index, train_data, label='Training Data', color='blue')\n",
    "    plt.plot(test_data.index, test_data, label='Actual Test Data', color='orange')\n",
    "    plt.plot(forecast.index, forecast, label='ARIMA Forecast', linestyle='--', color='green')\n",
    "    plt.title(f\"ARIMA Forecast for {rep}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    mae = mean_absolute_error(test_data, forecast)\n",
    "    rmse = np.sqrt(mean_squared_error(test_data, forecast))\n",
    "    mape = np.mean(np.abs((test_data - forecast) / test_data)) * 100\n",
    "\n",
    "    print(f\"Evaluation Metrics for {rep}:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ba333-8eda-4a8a-8888-7f697fc7f329",
   "metadata": {},
   "source": [
    "Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a702009-4861-489d-8dec-bedd7f94dbae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66bb2b8-bc98-4855-8b4f-543a5940fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Step 1: Load and prepare data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your CSV file name\n",
    "crypto_data = crypto_data.set_index(\"Ticker\")  # Set Ticker as index for filtering individual cryptocurrencies\n",
    "\n",
    "# Specify the cryptocurrency for analysis\n",
    "rep = \"SOL-USD\"  # Replace with your desired cryptocurrency\n",
    "\n",
    "# Extract data for the chosen cryptocurrency\n",
    "price_data = crypto_data.loc[rep].copy()\n",
    "\n",
    "# Ensure index is in datetime format and clean the data\n",
    "price_data_clean = price_data.drop(labels=[\"Cluster\"], errors=\"ignore\")  # Drop 'Cluster' if present\n",
    "price_data_clean.index = pd.to_datetime(price_data_clean.index, errors='coerce', format='%Y-%m-%d')\n",
    "price_data_clean = price_data_clean.dropna()  # Drop rows with invalid dates\n",
    "price_data_clean = price_data_clean.sort_index()  # Sort by date\n",
    "\n",
    "# Step 2: Train-test split\n",
    "train_data = price_data_clean[:-30]  # Use all but the last 30 points for training\n",
    "test_data = price_data_clean[-30:]   # Use the last 30 points for testing\n",
    "\n",
    "# Step 3: Fit the Holt-Winters model\n",
    "model = ExponentialSmoothing(\n",
    "    train_data,\n",
    "    trend=\"mul\",  # Multiplicative trend\n",
    "    seasonal=None,  # No seasonality\n",
    "    initialization_method=\"estimated\"  # Automatically initialize\n",
    ")\n",
    "hw_fit = model.fit()\n",
    "\n",
    "# Step 4: Forecast the next 30 days\n",
    "forecast = hw_fit.forecast(steps=30)\n",
    "forecast.index = test_data.index  # Align forecast index with test data\n",
    "\n",
    "# Step 5: Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data, label=\"Training Data\", color=\"blue\")\n",
    "plt.plot(test_data.index, test_data, label=\"Actual Test Data\", color=\"orange\")\n",
    "plt.plot(forecast.index, forecast, label=\"Holt-Winters Forecast\", linestyle=\"--\", color=\"green\")\n",
    "plt.title(f\"Holt-Winters Exponential Smoothing Forecast for {rep}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(test_data, forecast)\n",
    "rmse = mean_squared_error(test_data, forecast, squared=False)\n",
    "mape = (abs((test_data - forecast) / test_data).mean()) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for {rep}:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab209e-c99d-4cfd-9a48-9e316b6ead89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Step 1: Load and prepare data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your CSV file name\n",
    "crypto_data = crypto_data.set_index(\"Ticker\")  # Set Ticker as index for filtering individual cryptocurrencies\n",
    "\n",
    "# Specify the cryptocurrency for analysis\n",
    "rep = \"BTC-USD\"  # Replace with your desired cryptocurrency\n",
    "\n",
    "# Extract data for the chosen cryptocurrency\n",
    "price_data = crypto_data.loc[rep].copy()\n",
    "\n",
    "# Ensure index is in datetime format and clean the data\n",
    "price_data_clean = price_data.drop(labels=[\"Cluster\"], errors=\"ignore\")  # Drop 'Cluster' if present\n",
    "price_data_clean.index = pd.to_datetime(price_data_clean.index, errors='coerce', format='%Y-%m-%d')\n",
    "price_data_clean = price_data_clean.dropna()  # Drop rows with invalid dates\n",
    "price_data_clean = price_data_clean.sort_index()  # Sort by date\n",
    "\n",
    "# Step 2: Train-test split\n",
    "train_data = price_data_clean[:-30]  # Use all but the last 30 points for training\n",
    "test_data = price_data_clean[-30:]   # Use the last 30 points for testing\n",
    "\n",
    "# Step 3: Fit the Holt-Winters model\n",
    "model = ExponentialSmoothing(\n",
    "    train_data,\n",
    "    trend=\"mul\",  # Multiplicative trend\n",
    "    seasonal=None,  # No seasonality\n",
    "    initialization_method=\"estimated\"  # Automatically initialize\n",
    ")\n",
    "hw_fit = model.fit()\n",
    "\n",
    "# Step 4: Forecast the next 30 days\n",
    "forecast = hw_fit.forecast(steps=30)\n",
    "forecast.index = test_data.index  # Align forecast index with test data\n",
    "\n",
    "# Step 5: Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data, label=\"Training Data\", color=\"blue\")\n",
    "plt.plot(test_data.index, test_data, label=\"Actual Test Data\", color=\"orange\")\n",
    "plt.plot(forecast.index, forecast, label=\"Holt-Winters Forecast\", linestyle=\"--\", color=\"green\")\n",
    "plt.title(f\"Holt-Winters Exponential Smoothing Forecast for {rep}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(test_data, forecast)\n",
    "rmse = mean_squared_error(test_data, forecast, squared=False)\n",
    "mape = (abs((test_data - forecast) / test_data).mean()) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for {rep}:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f410139-84df-4954-9a2a-4eba996e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Step 1: Load and prepare data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your CSV file name\n",
    "crypto_data = crypto_data.set_index(\"Ticker\")  # Set Ticker as index for filtering individual cryptocurrencies\n",
    "\n",
    "# Specify the cryptocurrency for analysis\n",
    "rep = \"ETH-USD\"  # Replace with your desired cryptocurrency\n",
    "\n",
    "# Extract data for the chosen cryptocurrency\n",
    "price_data = crypto_data.loc[rep].copy()\n",
    "\n",
    "# Ensure index is in datetime format and clean the data\n",
    "price_data_clean = price_data.drop(labels=[\"Cluster\"], errors=\"ignore\")  # Drop 'Cluster' if present\n",
    "price_data_clean.index = pd.to_datetime(price_data_clean.index, errors='coerce', format='%Y-%m-%d')\n",
    "price_data_clean = price_data_clean.dropna()  # Drop rows with invalid dates\n",
    "price_data_clean = price_data_clean.sort_index()  # Sort by date\n",
    "\n",
    "# Step 2: Train-test split\n",
    "train_data = price_data_clean[:-30]  # Use all but the last 30 points for training\n",
    "test_data = price_data_clean[-30:]   # Use the last 30 points for testing\n",
    "\n",
    "# Step 3: Fit the Holt-Winters model\n",
    "model = ExponentialSmoothing(\n",
    "    train_data,\n",
    "    trend=\"mul\",  # Multiplicative trend\n",
    "    seasonal=None,  # No seasonality\n",
    "    initialization_method=\"estimated\"  # Automatically initialize\n",
    ")\n",
    "hw_fit = model.fit()\n",
    "\n",
    "# Step 4: Forecast the next 30 days\n",
    "forecast = hw_fit.forecast(steps=30)\n",
    "forecast.index = test_data.index  # Align forecast index with test data\n",
    "\n",
    "# Step 5: Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data, label=\"Training Data\", color=\"blue\")\n",
    "plt.plot(test_data.index, test_data, label=\"Actual Test Data\", color=\"orange\")\n",
    "plt.plot(forecast.index, forecast, label=\"Holt-Winters Forecast\", linestyle=\"--\", color=\"green\")\n",
    "plt.title(f\"Holt-Winters Exponential Smoothing Forecast for {rep}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(test_data, forecast)\n",
    "rmse = mean_squared_error(test_data, forecast, squared=False)\n",
    "mape = (abs((test_data - forecast) / test_data).mean()) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for {rep}:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c6f9f-e9ac-4353-b5db-6909d363bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Step 1: Load and prepare data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your CSV file name\n",
    "crypto_data = crypto_data.set_index(\"Ticker\")  # Set Ticker as index for filtering individual cryptocurrencies\n",
    "\n",
    "# Specify the cryptocurrency for analysis\n",
    "rep = \"XMR-USD\"  # Replace with your desired cryptocurrency\n",
    "\n",
    "# Extract data for the chosen cryptocurrency\n",
    "price_data = crypto_data.loc[rep].copy()\n",
    "\n",
    "# Ensure index is in datetime format and clean the data\n",
    "price_data_clean = price_data.drop(labels=[\"Cluster\"], errors=\"ignore\")  # Drop 'Cluster' if present\n",
    "price_data_clean.index = pd.to_datetime(price_data_clean.index, errors='coerce', format='%Y-%m-%d')\n",
    "price_data_clean = price_data_clean.dropna()  # Drop rows with invalid dates\n",
    "price_data_clean = price_data_clean.sort_index()  # Sort by date\n",
    "\n",
    "# Step 2: Train-test split\n",
    "train_data = price_data_clean[:-30]  # Use all but the last 30 points for training\n",
    "test_data = price_data_clean[-30:]   # Use the last 30 points for testing\n",
    "\n",
    "# Step 3: Fit the Holt-Winters model\n",
    "model = ExponentialSmoothing(\n",
    "    train_data,\n",
    "    trend=\"mul\",  # Multiplicative trend\n",
    "    seasonal=None,  # No seasonality\n",
    "    initialization_method=\"estimated\"  # Automatically initialize\n",
    ")\n",
    "hw_fit = model.fit()\n",
    "\n",
    "# Step 4: Forecast the next 30 days\n",
    "forecast = hw_fit.forecast(steps=30)\n",
    "forecast.index = test_data.index  # Align forecast index with test data\n",
    "\n",
    "# Step 5: Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data, label=\"Training Data\", color=\"blue\")\n",
    "plt.plot(test_data.index, test_data, label=\"Actual Test Data\", color=\"orange\")\n",
    "plt.plot(forecast.index, forecast, label=\"Holt-Winters Forecast\", linestyle=\"--\", color=\"green\")\n",
    "plt.title(f\"Holt-Winters Exponential Smoothing Forecast for {rep}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluation metrics\n",
    "mae = mean_absolute_error(test_data, forecast)\n",
    "rmse = mean_squared_error(test_data, forecast, squared=False)\n",
    "mape = (abs((test_data - forecast) / test_data).mean()) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for {rep}:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239f8f3-c112-4ca1-a01a-4c7970693ac0",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6483fd-1168-47a9-8c4a-5d9a4b6f6826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabb200-a40d-4700-bea7-542eccc0117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Update to the correct file name\n",
    "\n",
    "# Filter for the cryptocurrency of interest (e.g., SOL-USD)\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'SOL-USD'].iloc[:, 1:-1]  # Exclude Ticker and Cluster columns\n",
    "price_data = price_data.T  # Transpose to make dates the index\n",
    "price_data.index = pd.to_datetime(price_data.index, errors='coerce')  # Ensure the index is datetime\n",
    "price_data = price_data.dropna()  # Drop any rows with invalid dates\n",
    "price_data = price_data.squeeze()  # Convert to a series for easier manipulation\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(price_data.values, window_size)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train XGBoost Model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# Fix MAPE to handle zero values in y_test\n",
    "non_zero_indices = y_test != 0  # Identify indices where y_test is non-zero\n",
    "mape = np.mean(np.abs((y_test[non_zero_indices] - y_pred[non_zero_indices]) / y_test[non_zero_indices])) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for XGBoost SOL-USD:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Visualize Predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(price_data.index[-len(y_test):], y_test, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(price_data.index[-len(y_test):], y_pred, label=\"Predicted Prices\", color=\"orange\")\n",
    "plt.title(\"XGBoost Model SOL Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce23e94-0003-4442-ad63-6f1806b76f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Update to the correct file name\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'BTC-USD'].iloc[:, 1:-1].values.flatten()  # Replace with the desired cryptocurrency\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(price_data, window_size)\n",
    "\n",
    "# Walk-Forward Validation\n",
    "n_splits = 10  # Number of folds\n",
    "fold_size = len(X) // n_splits\n",
    "\n",
    "results = []\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    train_end = (i + 1) * fold_size\n",
    "    test_end = min(len(X), train_end + fold_size)\n",
    "\n",
    "    # Train-test split for the current fold\n",
    "    X_train, y_train = X[:train_end], y[:train_end]\n",
    "    X_test, y_test = X[train_end:test_end], y[train_end:test_end]\n",
    "\n",
    "    if len(y_test) == 0 or len(X_train) == 0:  # Skip invalid splits\n",
    "        continue\n",
    "\n",
    "    # Train XGBoost model\n",
    "    xgb_model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and collect metrics\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_test_all.extend(y_test)\n",
    "    y_pred_all.extend(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "    results.append({'MAE': mae, 'RMSE': rmse, 'MAPE': mape})\n",
    "\n",
    "    print(f\"Fold {i + 1} Results:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Calculate Average Results\n",
    "average_results = {metric: np.mean([r[metric] for r in results]) for metric in results[0]}\n",
    "print(\"\\nAverage Walk-Forward Validation Results:\")\n",
    "for metric, value in average_results.items():\n",
    "    print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "# Plot Final Predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(y_test_all)), y_test_all, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(range(len(y_pred_all)), y_pred_all, label=\"Predicted Prices\", color=\"orange\", linestyle=\"--\")\n",
    "plt.title(\"Final XGBoost Model BTC Predictions with Walk-Forward Validation\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3fc0e-67c1-49e9-a307-c50cbbc79a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Update to the correct file name\n",
    "\n",
    "# Filter for the cryptocurrency of interest (e.g., SOL-USD)\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'ETH-USD'].iloc[:, 1:-1]  # Exclude Ticker and Cluster columns\n",
    "price_data = price_data.T  # Transpose to make dates the index\n",
    "price_data.index = pd.to_datetime(price_data.index, errors='coerce')  # Ensure the index is datetime\n",
    "price_data = price_data.dropna()  # Drop any rows with invalid dates\n",
    "price_data = price_data.squeeze()  # Convert to a series for easier manipulation\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(price_data.values, window_size)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train XGBoost Model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# Fix MAPE to handle zero values in y_test\n",
    "non_zero_indices = y_test != 0  # Identify indices where y_test is non-zero\n",
    "mape = np.mean(np.abs((y_test[non_zero_indices] - y_pred[non_zero_indices]) / y_test[non_zero_indices])) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for XGBoost ETH-USD:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Visualize Predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(price_data.index[-len(y_test):], y_test, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(price_data.index[-len(y_test):], y_pred, label=\"Predicted Prices\", color=\"orange\")\n",
    "plt.title(\"XGBoost Model ETH Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc518a-782c-4653-928e-8fb0ca8f550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Update to the correct file name\n",
    "\n",
    "# Filter for the cryptocurrency of interest (e.g., SOL-USD)\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'XMR-USD'].iloc[:, 1:-1]  # Exclude Ticker and Cluster columns\n",
    "price_data = price_data.T  # Transpose to make dates the index\n",
    "price_data.index = pd.to_datetime(price_data.index, errors='coerce')  # Ensure the index is datetime\n",
    "price_data = price_data.dropna()  # Drop any rows with invalid dates\n",
    "price_data = price_data.squeeze()  # Convert to a series for easier manipulation\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(price_data.values, window_size)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train XGBoost Model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# Fix MAPE to handle zero values in y_test\n",
    "non_zero_indices = y_test != 0  # Identify indices where y_test is non-zero\n",
    "mape = np.mean(np.abs((y_test[non_zero_indices] - y_pred[non_zero_indices]) / y_test[non_zero_indices])) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for XGBoost SOL-USD:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Visualize Predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(price_data.index[-len(y_test):], y_test, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(price_data.index[-len(y_test):], y_pred, label=\"Predicted Prices\", color=\"orange\")\n",
    "plt.title(\"XGBoost Model XMR Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbbbd3d-d16a-4618-810e-68518e2d315b",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a2247-d598-4782-b462-11a9afee88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your file name\n",
    "\n",
    "# Identify date-related columns (if applicable)\n",
    "date_columns = [col for col in crypto_data.columns if col != 'Ticker']\n",
    "\n",
    "# Convert only valid date columns to datetime while keeping others unchanged\n",
    "crypto_data.columns = [\n",
    "    pd.to_datetime(col, errors='coerce') if col in date_columns else col\n",
    "    for col in crypto_data.columns\n",
    "]\n",
    "\n",
    "# Ensure the 'Ticker' column remains intact\n",
    "if 'Ticker' not in crypto_data.columns:\n",
    "    raise ValueError(\"The 'Ticker' column is missing in the CSV file.\")\n",
    "\n",
    "# Filter and reshape the data for the specific ticker\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'SOL-USD'].iloc[:, 1:-1].T  # Transpose to make dates the index\n",
    "price_data.index = pd.to_datetime(price_data.index, errors='coerce')  # Ensure the index is datetime\n",
    "price_data = price_data.dropna()  # Drop rows with invalid dates\n",
    "\n",
    "# Extract dates and values\n",
    "dates = price_data.index\n",
    "prices = price_data.values.flatten()\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(prices, window_size)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "dates_test = dates[train_size + window_size:] \n",
    "\n",
    "# Scale Features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVR Model\n",
    "svr_model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for SVR SOL-USD:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Visualize Predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates_test, y_test, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(dates_test, y_pred, label=\"Predicted Prices\", color=\"orange\", linestyle=\"--\")\n",
    "plt.title(\"SVR Model SOL Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da87c-e738-4ce7-8a3a-39c41a7cae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your file name\n",
    "\n",
    "# Identify date-related columns (if applicable)\n",
    "date_columns = [col for col in crypto_data.columns if col != 'Ticker']\n",
    "\n",
    "# Convert only valid date columns to datetime while keeping others unchanged\n",
    "crypto_data.columns = [\n",
    "    pd.to_datetime(col, errors='coerce') if col in date_columns else col\n",
    "    for col in crypto_data.columns\n",
    "]\n",
    "\n",
    "# Ensure the 'Ticker' column remains intact\n",
    "if 'Ticker' not in crypto_data.columns:\n",
    "    raise ValueError(\"The 'Ticker' column is missing in the CSV file.\")\n",
    "\n",
    "# Filter and reshape the data for the specific ticker\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'BTC-USD'].iloc[:, 1:-1].T  # Transpose to make dates the index\n",
    "price_data.index = pd.to_datetime(price_data.index, errors='coerce')  # Ensure the index is datetime\n",
    "price_data = price_data.dropna()  # Drop rows with invalid dates\n",
    "\n",
    "# Extract dates and values\n",
    "dates = price_data.index\n",
    "prices = price_data.values.flatten()\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(prices, window_size)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "dates_test = dates[train_size + window_size:]  # Align test dates with predictions\n",
    "\n",
    "# Scale Features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVR Model\n",
    "svr_model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for SVR BTC-USD:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Visualize Predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates_test, y_test, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(dates_test, y_pred, label=\"Predicted Prices\", color=\"orange\", linestyle=\"--\")\n",
    "plt.title(\"SVR Model BTC Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda6198-d0a8-49a2-8586-15e9d2b43569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your file name\n",
    "\n",
    "# Identify date-related columns (if applicable)\n",
    "date_columns = [col for col in crypto_data.columns if col != 'Ticker']\n",
    "\n",
    "# Convert only valid date columns to datetime while keeping others unchanged\n",
    "crypto_data.columns = [\n",
    "    pd.to_datetime(col, errors='coerce') if col in date_columns else col\n",
    "    for col in crypto_data.columns\n",
    "]\n",
    "\n",
    "# Ensure the 'Ticker' column remains intact\n",
    "if 'Ticker' not in crypto_data.columns:\n",
    "    raise ValueError(\"The 'Ticker' column is missing in the CSV file.\")\n",
    "\n",
    "# Filter and reshape the data for the specific ticker\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'ETH-USD'].iloc[:, 1:-1].T  # Transpose to make dates the index\n",
    "price_data.index = pd.to_datetime(price_data.index, errors='coerce')  # Ensure the index is datetime\n",
    "price_data = price_data.dropna()  # Drop rows with invalid dates\n",
    "\n",
    "# Extract dates and values\n",
    "dates = price_data.index\n",
    "prices = price_data.values.flatten()\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(prices, window_size)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "dates_test = dates[train_size + window_size:]  # Align test dates with predictions\n",
    "\n",
    "# Scale Features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVR Model\n",
    "svr_model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for SVR ETH-USD:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Visualize Predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates_test, y_test, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(dates_test, y_pred, label=\"Predicted Prices\", color=\"orange\", linestyle=\"--\")\n",
    "plt.title(\"SVR Model ETH Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de171bbd-36ef-4c5e-8ba5-208f0f029bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "crypto_data = pd.read_csv(\"Clustering.csv\")  # Replace with your file name\n",
    "\n",
    "# Identify date-related columns (if applicable)\n",
    "date_columns = [col for col in crypto_data.columns if col != 'Ticker']\n",
    "\n",
    "# Convert only valid date columns to datetime while keeping others unchanged\n",
    "crypto_data.columns = [\n",
    "    pd.to_datetime(col, errors='coerce') if col in date_columns else col\n",
    "    for col in crypto_data.columns\n",
    "]\n",
    "\n",
    "# Ensure the 'Ticker' column remains intact\n",
    "if 'Ticker' not in crypto_data.columns:\n",
    "    raise ValueError(\"The 'Ticker' column is missing in the CSV file.\")\n",
    "\n",
    "# Filter and reshape the data for the specific ticker\n",
    "price_data = crypto_data[crypto_data['Ticker'] == 'XMR-USD'].iloc[:, 1:-1].T  # Transpose to make dates the index\n",
    "price_data.index = pd.to_datetime(price_data.index, errors='coerce')  # Ensure the index is datetime\n",
    "price_data = price_data.dropna()  # Drop rows with invalid dates\n",
    "\n",
    "# Extract dates and values\n",
    "dates = price_data.index\n",
    "prices = price_data.values.flatten()\n",
    "\n",
    "# Prepare Sliding Window Data\n",
    "def create_features(data, window_size=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 5\n",
    "X, y = create_features(prices, window_size)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "dates_test = dates[train_size + window_size:]  # Align test dates with predictions\n",
    "\n",
    "# Scale Features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVR Model\n",
    "svr_model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"Evaluation Metrics for SVR XMR-USD:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Visualize Predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates_test, y_test, label=\"Actual Prices\", color=\"blue\")\n",
    "plt.plot(dates_test, y_pred, label=\"Predicted Prices\", color=\"orange\", linestyle=\"--\")\n",
    "plt.title(\"SVR Model XMR Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f52ac7-cf41-4ba3-8412-8825e99f65d8",
   "metadata": {},
   "source": [
    "STEP 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea50ed-d0af-484c-aec6-4ac9f7639807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
